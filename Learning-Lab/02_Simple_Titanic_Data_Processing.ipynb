{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Titanic Data Processing - One Step at a Time\n",
    "\n",
    "Welcome to your first hands-on data processing experience! ğŸš¢\n",
    "\n",
    "In this notebook, we'll work with the famous Titanic dataset and learn data processing **one simple step at a time**. Each step focuses on a single concept, making it easy to understand and practice.\n",
    "\n",
    "## About the Titanic Dataset\n",
    "The Titanic dataset contains information about passengers aboard the RMS Titanic. We'll use this real-world data to learn essential data processing skills.\n",
    "\n",
    "## What You'll Learn (Step by Step):\n",
    "1. Load and view the dataset\n",
    "2. Find missing values in a specific column\n",
    "3. Find all categorical columns\n",
    "4. Find all numerical columns\n",
    "5. Count unique values in categorical columns\n",
    "6. Check data types\n",
    "7. Get basic statistics\n",
    "8. And much more!\n",
    "\n",
    "Let's start our journey! ğŸ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data\n",
    "\n",
    "First, let's import the libraries we need and load our Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ“š Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "print(\"ğŸš¢ Titanic dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"This means we have {df.shape[0]} rows (passengers) and {df.shape[1]} columns (features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: View the First Few Rows\n",
    "\n",
    "Let's see what our data looks like by viewing the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the dataset\n",
    "print(\"ğŸ‘€ First 5 rows of the Titanic dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: See All Column Names\n",
    "\n",
    "Let's see what columns (features) we have in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all column names\n",
    "print(\"ğŸ“‹ All columns in the dataset:\")\n",
    "for i, column in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {column}\")\n",
    "\n",
    "print(f\"\\nTotal number of columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Find Missing Values in a Specific Column\n",
    "\n",
    "Let's check for missing values in the 'age' column specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in the 'age' column\n",
    "column_name = 'age'\n",
    "\n",
    "missing_count = df[column_name].isnull().sum()\n",
    "total_count = len(df[column_name])\n",
    "missing_percentage = (missing_count / total_count) * 100\n",
    "\n",
    "print(f\"ğŸ” Missing values analysis for '{column_name}' column:\")\n",
    "print(f\"Missing values: {missing_count}\")\n",
    "print(f\"Total values: {total_count}\")\n",
    "print(f\"Missing percentage: {missing_percentage:.2f}%\")\n",
    "\n",
    "if missing_count > 0:\n",
    "    print(f\"\\nâš ï¸  The '{column_name}' column has missing values!\")\n",
    "else:\n",
    "    print(f\"\\nâœ… The '{column_name}' column has no missing values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Find Missing Values in ALL Columns\n",
    "\n",
    "Now let's check missing values in all columns at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in all columns\n",
    "print(\"ğŸ” Missing values in ALL columns:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(df)) * 100\n",
    "\n",
    "# Create a summary table\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': missing_data.index,\n",
    "    'Missing Count': missing_data.values,\n",
    "    'Missing %': missing_percentage.values\n",
    "})\n",
    "\n",
    "# Sort by missing count (highest first)\n",
    "missing_summary = missing_summary.sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(missing_summary)\n",
    "\n",
    "# Show only columns with missing values\n",
    "columns_with_missing = missing_summary[missing_summary['Missing Count'] > 0]\n",
    "print(f\"\\nğŸ“Š Summary: {len(columns_with_missing)} columns have missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Find All Categorical Columns\n",
    "\n",
    "Let's identify which columns contain categorical (text/string) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Find columns with 'object' data type (usually categorical)\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"ğŸ“ Categorical columns (object data type):\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "for i, column in enumerate(categorical_columns, 1):\n",
    "    unique_count = df[column].nunique()\n",
    "    print(f\"{i:2d}. {column:<15} (has {unique_count} unique values)\")\n",
    "\n",
    "print(f\"\\nTotal categorical columns: {len(categorical_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see some examples from each categorical column\n",
    "print(\"ğŸ” Sample values from each categorical column:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for column in categorical_columns:\n",
    "    print(f\"\\n{column}:\")\n",
    "    # Show first 5 unique values (excluding NaN)\n",
    "    unique_values = df[column].dropna().unique()[:5]\n",
    "    for value in unique_values:\n",
    "        print(f\"  - {value}\")\n",
    "    \n",
    "    if len(df[column].dropna().unique()) > 5:\n",
    "        print(f\"  ... and {len(df[column].dropna().unique()) - 5} more values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Find All Numerical Columns\n",
    "\n",
    "Now let's identify columns that contain numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with numerical data types\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"ğŸ”¢ Numerical columns:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    data_type = df[column].dtype\n",
    "    min_val = df[column].min()\n",
    "    max_val = df[column].max()\n",
    "    print(f\"{i:2d}. {column:<15} ({data_type}) - Range: {min_val} to {max_val}\")\n",
    "\n",
    "print(f\"\\nTotal numerical columns: {len(numerical_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Check Data Types of All Columns\n",
    "\n",
    "Let's see the data type of each column in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types of all columns\n",
    "print(\"ğŸ“Š Data types of all columns:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "data_types = df.dtypes\n",
    "\n",
    "for column, dtype in data_types.items():\n",
    "    print(f\"{column:<15} : {dtype}\")\n",
    "\n",
    "# Summary of data types\n",
    "print(\"\\nğŸ“ˆ Summary of data types:\")\n",
    "type_counts = df.dtypes.value_counts()\n",
    "for dtype, count in type_counts.items():\n",
    "    print(f\"{dtype}: {count} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Count Unique Values in Categorical Columns\n",
    "\n",
    "For each categorical column, let's see how many unique values it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values in each categorical column\n",
    "print(\"ğŸ” Unique value counts for categorical columns:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for column in categorical_columns:\n",
    "    unique_count = df[column].nunique()\n",
    "    total_count = df[column].count()  # Non-null values\n",
    "    \n",
    "    print(f\"\\n{column}:\")\n",
    "    print(f\"  Unique values: {unique_count}\")\n",
    "    print(f\"  Non-null values: {total_count}\")\n",
    "    \n",
    "    # Show the actual unique values if there are not too many\n",
    "    if unique_count <= 10:\n",
    "        print(f\"  Values: {list(df[column].dropna().unique())}\")\n",
    "    else:\n",
    "        print(f\"  (Too many unique values to display - showing first 5)\")\n",
    "        print(f\"  Sample values: {list(df[column].dropna().unique()[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Get Basic Statistics for Numerical Columns\n",
    "\n",
    "Let's get some basic statistics (mean, median, etc.) for our numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic statistics for numerical columns\n",
    "print(\"ğŸ“Š Basic statistics for numerical columns:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "numerical_stats = df[numerical_columns].describe()\n",
    "print(numerical_stats)\n",
    "\n",
    "print(\"\\nğŸ’¡ What these statistics mean:\")\n",
    "print(\"  count: Number of non-missing values\")\n",
    "print(\"  mean:  Average value\")\n",
    "print(\"  std:   Standard deviation (how spread out the values are)\")\n",
    "print(\"  min:   Smallest value\")\n",
    "print(\"  25%:   25th percentile (1st quartile)\")\n",
    "print(\"  50%:   50th percentile (median)\")\n",
    "print(\"  75%:   75th percentile (3rd quartile)\")\n",
    "print(\"  max:   Largest value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Focus on a Specific Column - Age Analysis\n",
    "\n",
    "Let's do a detailed analysis of the 'age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of the 'age' column\n",
    "print(\"ğŸ‘¶ğŸ‘´ Detailed Age Analysis:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "age_column = df['age']\n",
    "\n",
    "# Basic information\n",
    "print(f\"Total passengers: {len(age_column)}\")\n",
    "print(f\"Ages recorded: {age_column.count()}\")\n",
    "print(f\"Missing ages: {age_column.isnull().sum()}\")\n",
    "print(f\"Missing percentage: {(age_column.isnull().sum() / len(age_column)) * 100:.1f}%\")\n",
    "\n",
    "# Age statistics (only for non-missing values)\n",
    "print(f\"\\nğŸ“Š Age Statistics:\")\n",
    "print(f\"Youngest passenger: {age_column.min():.1f} years old\")\n",
    "print(f\"Oldest passenger: {age_column.max():.1f} years old\")\n",
    "print(f\"Average age: {age_column.mean():.1f} years old\")\n",
    "print(f\"Median age: {age_column.median():.1f} years old\")\n",
    "\n",
    "# Age groups\n",
    "print(f\"\\nğŸ‘¶ Age Groups:\")\n",
    "children = age_column[age_column < 18].count()\n",
    "adults = age_column[(age_column >= 18) & (age_column < 65)].count()\n",
    "seniors = age_column[age_column >= 65].count()\n",
    "\n",
    "print(f\"Children (< 18): {children} passengers\")\n",
    "print(f\"Adults (18-64): {adults} passengers\")\n",
    "print(f\"Seniors (65+): {seniors} passengers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Focus on a Specific Column - Sex Analysis\n",
    "\n",
    "Let's analyze the 'sex' column to understand the gender distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of the 'sex' column\n",
    "print(\"ğŸ‘¨ğŸ‘© Gender Distribution Analysis:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "sex_column = df['sex']\n",
    "\n",
    "# Basic information\n",
    "print(f\"Total passengers: {len(sex_column)}\")\n",
    "print(f\"Gender recorded: {sex_column.count()}\")\n",
    "print(f\"Missing gender info: {sex_column.isnull().sum()}\")\n",
    "\n",
    "# Gender distribution\n",
    "print(f\"\\nğŸ“Š Gender Distribution:\")\n",
    "gender_counts = sex_column.value_counts()\n",
    "gender_percentages = sex_column.value_counts(normalize=True) * 100\n",
    "\n",
    "for gender in gender_counts.index:\n",
    "    count = gender_counts[gender]\n",
    "    percentage = gender_percentages[gender]\n",
    "    print(f\"{gender.capitalize()}: {count} passengers ({percentage:.1f}%)\")\n",
    "\n",
    "# Show unique values\n",
    "print(f\"\\nğŸ” Unique values in sex column: {list(sex_column.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Focus on a Specific Column - Survival Analysis\n",
    "\n",
    "Let's analyze the 'survived' column - this is very important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of the 'survived' column\n",
    "print(\"ğŸš¢âš°ï¸  Survival Analysis:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "survived_column = df['survived']\n",
    "\n",
    "# Basic information\n",
    "print(f\"Total passengers: {len(survived_column)}\")\n",
    "print(f\"Survival info available: {survived_column.count()}\")\n",
    "print(f\"Missing survival info: {survived_column.isnull().sum()}\")\n",
    "\n",
    "# Survival statistics\n",
    "print(f\"\\nğŸ“Š Survival Statistics:\")\n",
    "survival_counts = survived_column.value_counts().sort_index()\n",
    "survival_percentages = survived_column.value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "for status in survival_counts.index:\n",
    "    count = survival_counts[status]\n",
    "    percentage = survival_percentages[status]\n",
    "    status_text = \"Survived\" if status == 1 else \"Did not survive\"\n",
    "    print(f\"{status_text}: {count} passengers ({percentage:.1f}%)\")\n",
    "\n",
    "# Overall survival rate\n",
    "survival_rate = survived_column.mean() * 100\n",
    "print(f\"\\nğŸ’¡ Overall survival rate: {survival_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Find Columns with No Missing Values\n",
    "\n",
    "Let's identify which columns are complete (no missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with no missing values\n",
    "print(\"âœ… Columns with NO missing values:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "complete_columns = []\n",
    "incomplete_columns = []\n",
    "\n",
    "for column in df.columns:\n",
    "    missing_count = df[column].isnull().sum()\n",
    "    if missing_count == 0:\n",
    "        complete_columns.append(column)\n",
    "    else:\n",
    "        incomplete_columns.append((column, missing_count))\n",
    "\n",
    "# Show complete columns\n",
    "print(f\"Complete columns ({len(complete_columns)} total):\")\n",
    "for i, column in enumerate(complete_columns, 1):\n",
    "    print(f\"{i:2d}. {column}\")\n",
    "\n",
    "# Show incomplete columns\n",
    "print(f\"\\nâŒ Columns with missing values ({len(incomplete_columns)} total):\")\n",
    "for i, (column, missing_count) in enumerate(incomplete_columns, 1):\n",
    "    missing_percentage = (missing_count / len(df)) * 100\n",
    "    print(f\"{i:2d}. {column:<15} - {missing_count} missing ({missing_percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Simple Data Quality Check\n",
    "\n",
    "Let's do a simple overall data quality assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall data quality assessment\n",
    "print(\"ğŸ” Data Quality Assessment:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "total_cells = df.shape[0] * df.shape[1]\n",
    "missing_cells = df.isnull().sum().sum()\n",
    "complete_cells = total_cells - missing_cells\n",
    "\n",
    "print(f\"Dataset dimensions: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"Total cells: {total_cells:,}\")\n",
    "print(f\"Complete cells: {complete_cells:,} ({(complete_cells/total_cells)*100:.1f}%)\")\n",
    "print(f\"Missing cells: {missing_cells:,} ({(missing_cells/total_cells)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Column Summary:\")\n",
    "print(f\"Complete columns: {len(complete_columns)}\")\n",
    "print(f\"Columns with missing data: {len(incomplete_columns)}\")\n",
    "print(f\"Numerical columns: {len(numerical_columns)}\")\n",
    "print(f\"Categorical columns: {len(categorical_columns)}\")\n",
    "\n",
    "# Data quality score (simple)\n",
    "quality_score = (complete_cells / total_cells) * 100\n",
    "print(f\"\\nâ­ Data Quality Score: {quality_score:.1f}%\")\n",
    "\n",
    "if quality_score >= 90:\n",
    "    print(\"   Excellent data quality! ğŸŒŸ\")\n",
    "elif quality_score >= 80:\n",
    "    print(\"   Good data quality! ğŸ‘\")\n",
    "elif quality_score >= 70:\n",
    "    print(\"   Fair data quality - some cleaning needed ğŸ”§\")\n",
    "else:\n",
    "    print(\"   Poor data quality - significant cleaning needed âš ï¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Practice Exercises\n",
    "\n",
    "Now it's your turn! Try these simple exercises:\n",
    "\n",
    "### Exercise 1: Explore Another Column\n",
    "Pick any column from the dataset and do a detailed analysis like we did for 'age' and 'sex'.\n",
    "\n",
    "### Exercise 2: Find Specific Missing Values\n",
    "Find which passengers (rows) have missing age information.\n",
    "\n",
    "### Exercise 3: Simple Filtering\n",
    "Find all passengers who were:\n",
    "- Under 18 years old\n",
    "- Female\n",
    "- Survived the disaster\n",
    "\n",
    "### Exercise 4: Count and Compare\n",
    "Compare survival rates between different groups (male vs female, different passenger classes, etc.)\n",
    "\n",
    "Try these exercises in the cells below! ğŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Pick a column and analyze it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Find passengers with missing age information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "# Find specific groups of passengers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Your code here\n",
    "# Compare survival rates between groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "You've completed your first step-by-step data processing journey! ğŸš€\n",
    "\n",
    "### What You've Learned:\n",
    "âœ… How to load and explore a dataset  \n",
    "âœ… How to find missing values in specific columns  \n",
    "âœ… How to identify categorical and numerical columns  \n",
    "âœ… How to count unique values  \n",
    "âœ… How to check data types  \n",
    "âœ… How to get basic statistics  \n",
    "âœ… How to analyze specific columns in detail  \n",
    "âœ… How to assess overall data quality  \n",
    "\n",
    "### Next Steps:\n",
    "ğŸ”„ Practice with different datasets  \n",
    "ğŸ“Š Learn data visualization  \n",
    "ğŸ§¹ Learn data cleaning techniques  \n",
    "ğŸ”§ Learn feature engineering  \n",
    "\n",
    "Keep practicing and exploring! Every dataset tells a story - you're learning to read it! ğŸ“–âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
